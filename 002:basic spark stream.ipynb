{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Stream\n",
    "\n",
    "take data from stream, package it down into small batches, and provide them to Spark for further processing.\n",
    "\n",
    "![spark stream](files/images/spas_1601.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DStream \n",
    "Discretized stream represents a stream in terms of discrete blocks of data that in turn are represented as RDDS over time\n",
    "\n",
    "\n",
    "![dstream](files/images/spas_1602.png)\n",
    "![dstream](files/images/spas_1701.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ssc = org.apache.spark.streaming.StreamingContext@5564ece8\n",
       "dstream = org.apache.spark.streaming.dstream.SocketInputDStream@46e63feb\n",
       "countStream = org.apache.spark.streaming.dstream.MappedDStream@55ecfa4b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.streaming.dstream.MappedDStream@55ecfa4b"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create stream context\n",
    "import org.apache.spark.streaming._\n",
    "\n",
    "val ssc = new StreamingContext(spark.sparkContext, Seconds(10))\n",
    "val dstream = ssc.socketTextStream(\"localhost\", 9876)\n",
    "val countStream = dstream.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "countStream.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use netcat to simulate server side by\n",
    "```nc -l 9876```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 1583561520000 ms\n",
      "-------------------------------------------\n",
      "3\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583561530000 ms\n",
      "-------------------------------------------\n",
      "9\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583561540000 ms\n",
      "-------------------------------------------\n",
      "10\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583561550000 ms\n",
      "-------------------------------------------\n",
      "10\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583561560000 ms\n",
      "-------------------------------------------\n",
      "10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in thread \"receiver-supervisor-future-0\" java.lang.Error: java.lang.InterruptedException: sleep interrupted\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.lang.InterruptedException: sleep interrupted\n",
      "\tat java.lang.Thread.sleep(Native Method)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor$$anonfun$restartReceiver$1.apply$mcV$sp(ReceiverSupervisor.scala:196)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor$$anonfun$restartReceiver$1.apply(ReceiverSupervisor.scala:189)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor$$anonfun$restartReceiver$1.apply(ReceiverSupervisor.scala:189)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\t... 2 more\n"
     ]
    }
   ],
   "source": [
    "ssc.stop(stopSparkContext = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ssc = org.apache.spark.streaming.StreamingContext@1297da6d\n",
       "lines = org.apache.spark.streaming.dstream.SocketInputDStream@3752337a\n",
       "record = org.apache.spark.streaming.dstream.FlatMappedDStream@4367d14f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.streaming.dstream.FlatMappedDStream@4367d14f"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ssc = new StreamingContext(spark.sparkContext, Seconds(10))\n",
    "val lines = ssc.socketTextStream(\"localhost\", 9876)\n",
    "val record = lines.flatMap(_.split(\",\"))\n",
    "record.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 1583470900000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583470910000 ms\n",
      "-------------------------------------------\n",
      "helllo\n",
      " name\n",
      " pok\n",
      " 20\n",
      "bunny\n",
      " name\n",
      " pann\n",
      " 30\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583470920000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1583470930000 ms\n",
      "-------------------------------------------\n",
      "ppp\n",
      " yyy\n",
      " 20\n",
      " 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in thread \"receiver-supervisor-future-0\" java.lang.Error: java.lang.InterruptedException: sleep interrupted\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.lang.InterruptedException: sleep interrupted\n",
      "\tat java.lang.Thread.sleep(Native Method)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor$$anonfun$restartReceiver$1.apply$mcV$sp(ReceiverSupervisor.scala:196)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor$$anonfun$restartReceiver$1.apply(ReceiverSupervisor.scala:189)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor$$anonfun$restartReceiver$1.apply(ReceiverSupervisor.scala:189)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\t... 2 more\n"
     ]
    }
   ],
   "source": [
    "ssc.stop(stopSparkContext = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
